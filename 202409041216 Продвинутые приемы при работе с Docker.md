---
date:
  - 04/09/2024 12:16
tags: 
cssclasses:
  - image-borders
  - neutral-pen-black
---
При работе с Docker существуют расширенные функции и приемы, которые могут значительно повысить производительность и оптимизировать рабочие процессы. Ниже представлен список из 13 приемов Docker, предлагающих эффективные и менее известные способы его использования.

# **1. Многоступенчатые сборки для эффективного создания образов**

Многоступенчатые сборки в Docker — это мощный метод создания экономичных и более безопасных образов Docker путем отделения среды сборки от рабочей среды в одном файле Dockerfile. Этот метод не только помогает уменьшить конечный размер образа, но и минимизирует поверхность атаки, исключая ненужные инструменты и файлы из образа среды выполнения.

## **Что такое многоступенчатая сборка?**

Многоступенчатые сборки позволяют использовать несколько инструкций `FROM` в файле Dockerfile. Каждая инструкция `FROM` может использовать свою базу, и каждый этап может быть назван. Таким образом, вы можете копировать артефакты с одного этапа на другой, оставляя позади все, что вам не нужно видеть в конечном образе.

## **Как использовать многоступенчатые сборки**

```docker
# Syntax for multi-stage builds
# Stage 1: Build the application
FROM golang:1.15 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp .

# Stage 2: Create the final image
FROM alpine:latest
COPY --from=builder /app/myapp /app/myapp
ENTRYPOINT ["/app/myapp"]
```

В этом примере демонстрируется простая многоэтапная сборка для приложения Go. На этапе сборки используется образ Golang для компиляции приложения, а на заключительном этапе создается облегченный образ Alpine, содержащий только скомпилированный двоичный файл.

## **Когда следует использовать многоступенчатые сборки**

- **Уменьшение размера образа:** когда процесс сборки приложения включает в себя компиляцию кода или включение зависимостей времени сборки, которые не требуются во время выполнения.
- **Повышение безопасности:** Чтобы свести к минимуму поверхность атаки на конечный образ за счет исключения инструментов и файлов, которые не требуются для работы приложения.
- **Разделение сред сборки:** когда вам нужно создать приложения в определенной среде, но вы хотите запустить их в другой.

## **Рекомендации**

- **Оптимизация использования кэша сборки:** Заказывайте копию и выполняйте инструкции с осторожностью, чтобы максимизировать кэширование слоев.
- **Минимизировать окончательный размер образа:** Скопируйте в окончательный образ только артефакты, необходимые для запуска приложения.
- **Этапы сборки меток:** используйте именованные этапы для улучшения удобочитаемости и удобства обслуживания файла `Dockerfile`.

## **Распространенные подводные камни**

- Чрезмерное усложнение: избегайте излишне сложных многоступенчатых сборок, которые могут привести к сложным в обслуживании файлам `Dockerfile`.
- Игнорирование контекста сборки: Помните о контексте сборки, который вы отправляете демону Docker, так как излишне большие контексты могут замедлить процесс сборки.

## **Ссылки по теме**

- Документация по официальным многоступенчатым сборкам Docker: [https://docs.docker.com/develop/develop-images/multistage-build/](https://docs.docker.com/develop/develop-images/multistage-build/)
- Рекомендации по написанию Dockerфайлов: [https://docs.docker.com/develop/develop-images/dockerfile_best-practices/](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)

# **2. Сжимаем слои образа**

Сжатие слоев образов в Docker — это метод, который может значительно уменьшить их размер в Docker. Объединив все слои, созданные во время сборки образа, в один слой, можно оптимизировать хранение и распространение образов Docker.

## **Что такое squash?**

При создании образа Docker каждая инструкция в файле `Dockerfile` создает новый слой. Эти слои могут накапливать ненужные данные, что приводит к раздутым образам. Склеивание уменьшает количество слоев в образах Docker за счет их объединения в один, что может помочь свести к минимуму размер образа.

## **Как использовать squash**

Чтобы объединить слои образа, можно использовать флаг `--squash` при создании образов с включенным Docker BuildKit. Вот как вы можете включить BuildKit и использовать функцию сжатия:

```docker
# Enable Docker BuildKit
export DOCKER_BUILDKIT=1

# Build and squash the image
docker build --tag myapp:latest --squash .
```

<aside> ❗ Примечание: Флаг `--squash` является экспериментальной функцией и может потребовать от вас включения экспериментальных функций в вашей конфигурации Docker.

</aside>

## **Когда следует использовать squash**

- **Оптимизация размера образа:** используйте сжатие, когда вам нужно уменьшить размер конечного образа Docker, особенно при распространении образов по сети или хранении их в реестре.
- **Упрощение слоев образа:** если файл Dockerfile содержит много инструкций по запуску или копированию, которые увеличивают количество слоев и общий размер образа.

## **Рекомендации**

- **Выборочное сжатие:** Подумайте, какие образы больше всего выигрывают от сжатия.
    
    Некоторые слои лучше оставить несжатыми для кэширования, особенно во время разработки.
    
- **Помните о кэшировании:** сжатие может повлиять на механизм кэширования слоев Docker.
    
    Частое сжатие может привести к увеличению времени сборки, так как Docker не может эффективно кэшировать промежуточные слои.
    
- **Последствия для безопасности:** Поймите, что сжатие может скрыть историю образа.
    
    Убедитесь, что последний сжатый слой случайно не содержит конфиденциальные данные, которые должны быть отброшены в промежуточных слоях.
    

## **Распространенные подводные камни**

- **Чрезмерное использование во время разработки:** Сжатие после каждой сборки во время разработки может значительно замедлить время сборки из-за потери преимуществ кэширования.
- **Игнорирование экспериментального статуса:** помните, что функция сжатия является экспериментальной и может не работать одинаково в разных версиях или конфигурациях Docker.

## **Ссылки по теме**

- Документация по Docker BuildKit: [https://docs.docker.com/develop/develop-images/build_enhancements/](https://docs.docker.com/develop/develop-images/build_enhancements/)
- Рекомендации по работе с Dockerfile: [https://docs.docker.com/develop/develop-images/dockerfile_best-practices/](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)

# **3. Секреты Docker BuildKit**

Docker BuildKit предлагает более безопасный способ обработки секретов в процессе сборки, решая проблему использования частных ресурсов без их раскрытия в окончательном образе. Возможности управления секретами BuildKit позволяют передавать конфиденциальную информацию во время сборки, не оставляя следов в слоях образа.

## **Что такое секреты Docker BuildKit?**

Секреты Docker BuildKit — это функция системы сборки Docker BuildKit. Он позволяет безопасно передавать секретную информацию (например, пароли, закрытые ключи или токены API) в процесс сборки. Эти секреты не хранятся в окончательном образе или в промежуточных слоях, что делает процесс сборки более безопасным.

## **Как использовать секреты Docker BuildKit**

Чтобы использовать секреты Docker BuildKit, сначала убедитесь, что Docker BuildKit включен. Это можно сделать, установив переменную окружения `DOCKER_BUILDKIT=1`. Затем используйте флаг `--secret` во время процесса сборки, чтобы предоставить секреты.

```docker
# Enable Docker BuildKit
export DOCKER_BUILDKIT=1

# Build with a secret
docker build --secret id=mysecret,src=/path/to/secret/file.txt -t myapp:latest .
```

В Dockerfile вы можете получить доступ к секрету следующим образом:

```docker
# syntax=docker/dockerfile:1.2
FROM alpine
# Use the secret without exposing it in the image
RUN --mount=type=secret,id=mysecret cat /run/secrets/mysecret
```

## **Когда следует использовать секреты Docker BuildKit**

- **Доступ к частным репозиториям Git:** когда сборка требует извлечения зависимостей из частных репозиториев.
- **Использование закрытых ключей:** Когда вам нужно использовать закрытые ключи для доступа по SSH или для расшифровки файлов во время сборки.
- **Токены API:** когда процесс сборки включает в себя доступ к API, требующим аутентификации.

## **Рекомендации**

- **Сведите к минимуму раскрытие секретов:** Используйте секреты только в случае крайней необходимости и избегайте ведения журнала или их раскрытия на любых промежуточных этапах.
- **Секреты с ограниченной областью действия:** Четко определяйте и ограничивайте секреты конкретными этапами сборки, где они необходимы, снижая риск раскрытия.
- **Закрепление версии:** всегда закрепляйте версию синтаксиса в файле Dockerfile при использовании функций BuildKit, чтобы обеспечить совместимость и предсказуемость.

## **Распространенные подводные камни**

- **Жесткое кодирование секретов:** избегайте жесткого кодирования секретов или использования устаревших методов (например, `ARG` для передачи секретов), которые могут оставить конфиденциальную информацию в слоях образа.
- **Упущение из виду очистки:** Убедитесь, что в образе не осталось никаких секретных остатков, проверив последние слои или случайно создав кэшируемые слои с секретными данными.

## **Ссылки по теме**

- Документация по Docker BuildKit: [https://docs.docker.com/develop/develop-images/build_enhancements/#new-docker-build-secret-information](https://docs.docker.com/develop/develop-images/build_enhancements/#new-docker-build-secret-information)
- Рекомендации по использованию Docker BuildKit и безопасной работе с секретами: [https://www.docker.com/blog/intro-guide-to-dockerfile-best-practices/](https://www.docker.com/blog/intro-guide-to-dockerfile-best-practices/)

# **4. Использование `.dockerignore`**

Файл `.dockerignore` играет решающую роль в оптимизации сборок Docker, позволяя указывать шаблоны, исключающие файлы и каталоги из контекста, отправляемого управляющей программе Docker. Этот механизм может значительно ускорить процесс сборки, уменьшить размер контекста сборки и повысить безопасность за счет исключения конфиденциальных файлов.

## **Что такое `.dockerignore`?**

Как и `.gitignore`, файл `.dockerignore` сообщает Docker, какие файлы и каталоги следует игнорировать при сборке образа. Это особенно важно, потому что каждый файл, отправляемый управляющей программе Docker в рамках контекста сборки, может излишне увеличить время и сложность сборки, особенно в крупных проектах.

## **Как использовать `.dockerignore`**

Создайте файл `.dockerignore` в корне проекта, где находится ваш Dockerfile. В этом файле укажите шаблоны для файлов и каталогов, которые будут исключены из контекста сборки Docker.

## **Пример файла `.dockerignore`**

```docker
.git
.gitignore
Dockerfile*
*.md
node_modules
temp/
```

В этом примере метаданные Git, файлы Markdown, все файлы Docker, каталог `node_modules` и любой `temp` каталог не могут быть включены в контекст сборки Docker.

## **Когда следует использовать `.dockerignore`**

- **Большие репозитории:** для проектов с большими объемами данных, особенно тех, которые не нужны для сборки или выполнения во время выполнения.
- **Конфиденциальная информация:** чтобы исключить файлы, содержащие секреты или конфиденциальную информацию, которые не должны включаться в контекст сборки Docker.
- **Каталоги зависимостей:** для языков, которые загружают зависимости в локальные каталоги (например`node_modules` для Node.js), которые не нужны в контексте сборки, если вы устанавливаете зависимости во время сборки.

## **Рекомендации**

- **Регулярно проверяйте:** периодически проверяйте файл `.dockerignore` чтобы убедиться, что он соответствует структуре и требованиям вашего проекта.
- **Явные шаблоны:** Используйте явные шаблоны для точного сопоставления нужных файлов и каталогов, избегая непреднамеренных исключений.
- **Поддерживайте безопасность:** используйте `.dockerignore` для повышения безопасности, гарантируя, что в контекст сборки включены только необходимые файлы.

## **Распространенные подводные камни**

- **Упущение `.dockerignore`:** неиспользование или неправильная настройка файла `.dockerignore` может привести к медленным сборкам, увеличению размеров образов и потенциальному включению конфиденциальной информации.
- **Чрезмерное исключение:** Хотя важно исключать ненужные файлы, будьте осторожны, чтобы не исключать файлы, необходимые для процесса сборки, что может привести к сбоям сборки или неправильному поведению образа.

## **Ссылки по теме**

- Официальная документация Docker по `.dockerignore`: [https://docs.docker.com/engine/reference/builder/#dockerignore-file](https://docs.docker.com/engine/reference/builder/#dockerignore-file)
- Рекомендации по написанию файлов Docker, включая использование `.dockerignore`: [https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#exclude-with-dockerignore](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#exclude-with-dockerignore)

# **5. Проверки работоспособности в Dockerfiles**

Реализация проверок работоспособности непосредственно в Dockerfiles — это эффективный способ автоматического мониторинга рабочего состояния контейнеров. Определяя проверки работоспособности, Docker может принимать обоснованные решения о работоспособности контейнеров и предпринимать соответствующие действия, такие как перезапуск неисправного контейнера или запрет маршрутизации трафика к нему до тех пор, пока он не станет работоспособным.

## **Что такое проверка работоспособности Docker?**

Проверка работоспособности Docker — это команда, указанная в файле Docker, которую Docker периодически выполняет для проверки работоспособности контейнера. Эта команда должна указывать, правильно ли функционирует контейнер. Docker интерпретирует состояние выхода команды проверки работоспособности для определения состояния работоспособности контейнера: состояние выхода 0 означает работоспособное, а ненулевое — неработоспособное.

## **Как использовать проверки работоспособности в Dockerfiles**

Проверки работоспособности определяются в Dockerfile с помощью инструкции `HEALTHCHECK`. Можно указать команду для выполнения, интервал между проверками, время ожидания для каждой проверки, количество повторных попыток, прежде чем служба будет считаться неработоспособной, и период начала стабилизации контейнера перед началом проверок работоспособности.

## **Пример Dockerfile с проверкой работоспособности**

В этом примере задается проверка работоспособности контейнера Nginx, использующая `curl` для запроса главной страницы каждые 30 секунд. Если команда завершается ошибкой (страница возвращается некорректно) три раза подряд, Docker помечает контейнер как неработоспособный.

Проверка работоспособности использует `curl` для выполнения простого запроса к главной странице сервера Nginx. Docker будет выполнять эту проверку периодически, в соответствии с указанными интервалами, чтобы убедиться, что контейнер функционирует должным образом.

Сначала убедитесь, что ваш Dockerfile запускается с базового образа Nginx, а затем добавьте инструкцию `HEALTHCHECK` как показано ниже:

```docker
FROM nginx:latest

# Install curl for the health check.
RUN apt-get update && apt-get install -y curl && apt-get clean

# Copy over custom Nginx configuration files, if any.
# COPY default.conf /etc/nginx/conf.d/

HEALTHCHECK --interval=30s --timeout=30s --retries=3 --start-period=5s \\
  CMD curl -f <http://localhost/> || exit 1
```

`Dockerfile` выполняет следующие функции:

- Начинается с последнего образа Nginx.
    
- Устанавливает `curl` с помощью `apt-get` для использования для проверки работоспособности.
    
    (Примечание: образ Nginx основан на Debian, поэтому для установки используется `apt-get`.)
    
- (Дополнительно)
    
    Копирует любую пользовательскую конфигурацию Nginx, которая у вас может быть.
    
    Эта строка закомментирована, но включена в качестве примера того, где вы можете расширить Dockerfile.
    
- Определяет `HEALTHCHECK`, которая выполняется каждые 30 секунд (`-interval=30s`), истекает через 30 секунд (`-timeout=30s`), пытается достучаться 3 раза, прежде чем считает контейнер неработоспособным (`-retries=3`), и ждет 5 секунд перед началом проверки работоспособности (`-start-period=5s`).
    
    Фактическая проверка представляет собой `curl` на главную страницу сервера Nginx (`http://localhost/`).
    
    Если этот запрос завершается сбоем (`curl` завершится с ненулевым статусом, если он не сможет успешно выполнить HTTP-запрос), команда `exit 1` сигнализирует Docker о том, что контейнер неработоспособен.
    

## **Когда следует использовать проверку работоспособности**

- **Доступность службы:** когда необходимо убедиться, что служба в контейнере доступна и быстро реагирует, прежде чем отправлять в нее трафик.
- **Готовность к зависимостям:** В приложениях с несколькими контейнерами, где некоторые контейнеры зависят от полной работоспособности других.
- **Системы самовосстановления:** для создания более устойчивой системы, которая может автоматически перезапускать неработоспособные контейнеры.

## **Рекомендации**

- **Минимизация влияния на производительность:** убедитесь, что команда проверки работоспособности является упрощенной и не оказывает существенного влияния на производительность контейнера.
- **Точные начальные периоды:** Установите реалистичный `-start-period`, чтобы дать приложению достаточно времени для инициализации, прежде чем проверки работоспособности начнут завершаться неудачей.
- **Используйте определенные конечные точки работоспособности:** Отдавайте предпочтение использованию конкретных конечных точек (например, `/healthz`), которые проверяют работоспособность различных компонентов приложения, а не только главную страницу или базовую проверку TCP.

## **Распространенные подводные камни**

- **Сложные команды:** избегайте слишком сложных команд проверки работоспособности, которые могут быть ненадежными или вызывать неожиданные побочные эффекты.
- **Игнорирование внешних зависимостей:** если работоспособность контейнера зависит от внешних служб, убедитесь, что при проверке работоспособности учитывается их доступность, чтобы избежать ложных срабатываний.

## **Ссылки по теме**

- Справочник по Dockerfile для HEALTHCHECK: [https://docs.docker.com/engine/reference/builder/#healthcheck](https://docs.docker.com/engine/reference/builder/#healthcheck)
- Настройка проверки здоровья: [https://docs.docker.com/engine/reference/builder/#healthcheck-examples](https://docs.docker.com/engine/reference/builder/#healthcheck-examples)

# **6. Форматирование вывода Docker CLI**

Интерфейс командной строки (CLI) Docker предоставляет мощную функцию для настройки вывода команд с помощью параметра `--format`. Этот вариант использует язык шаблонов Go, чтобы пользователи могли точно указать, как должен быть структурирован вывод, что упрощает его анализ или интеграцию с другими инструментами.

## **Что такое форматирование вывода Docker CLI?**

Форматирование вывода Docker CLI позволяет настраивать вывод команд Docker в соответствии с вашими потребностями, используя язык шаблонов Go для указания формата вывода. Эта функция бесценна для извлечения определенных фрагментов информации из подробных выходных данных команд Docker, особенно при автоматизации задач или интеграции с конвейерами CI/CD.

## **Как использовать форматирование вывода Docker CLI**

Флаг `--format` можно использовать с различными командами Docker CLI для настройки их вывода. Вот пример того, как перечислить все идентификаторы контейнеров с помощью пользовательского формата:

```bash
docker ps --format '{{.ID}}'
```

Эта команда перечисляет идентификаторы всех запущенных контейнеров, по одному в строке, без какой-либо дополнительной информации или заголовков.

## **Продвинутый пример: Перечисление образов с определенными атрибутами**

Вот как вы можете перечислить образы, показывая только их репозиторий, тег и размер, в формате таблицы:

```bash
docker images --format "table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}"
```

Эта команда создает аккуратно отформатированную таблицу образов Docker, в которой отображаются только имя репозитория, тег и размер образа.

## **Когда следует использовать форматирование вывода Docker CLI**

- **Скрипты и автоматизация:** когда вам нужно проанализировать выходные данные команд Docker в скриптах или инструментах автоматизации.
- **Настраиваемые отчеты:** создание пользовательских отчетов или панелей мониторинга, для которых требуется определенная информация из среды Docker.
- **Упрощение вывода:** Когда вы хотите упростить вывод для ясности или сосредоточиться на конкретных деталях.

## **Рекомендации**

- **Понимание шаблонов Bash/Python/Go:** Ознакомьтесь с синтаксисом шаблонов, чтобы эффективно использовать параметры форматирования.
- **Используйте форматирование таблиц для удобства чтения:** используйте форматирование `table` для удобочитаемых выходных данных, особенно при обмене информацией с членами команды.
- **Комбинируйте с другими инструментами Unix:** Для еще более мощной обработки объедините отформатированный вывод Docker с инструментами Unix, такими как `grep`, `awk` или `jq` для вывода JSON.

## **Распространенные подводные камни**

- **Чрезмерное усложнение:** избегайте создания слишком сложных шаблонов, которые трудно читать и поддерживать.
    
    Сделайте его как можно более простым для выполнения поставленной задачи.
    
- **Несогласованное форматирование:** при использовании пользовательских форматов в разных скриптах или инструментах поддерживайте согласованность, чтобы избежать путаницы.
    

## **Ссылки по теме**

- Официальная документация Docker по форматированию: [https://docs.docker.com/config/formatting/](https://docs.docker.com/config/formatting/)
- Документаци] по языку шаблонов для более сложных задач форматирования (пример, Go): [https://golang.org/pkg/text/template/](https://golang.org/pkg/text/template/)

# **7. Оптимизация использования кэша в сборках**

Эффективное использование кэша сборки Docker может значительно ускорить создание образов за счет повторного использования ранее кэшированных слоев, а не их повторного построения. Это особенно важно для конвейеров итеративной разработки и непрерывной интеграции/непрерывного развертывания (CI/CD), где эффективность сборки может оказывать непосредственное влияние на производительность.

## **Что такое Docker Build Cache?**

Кэш сборки Docker — это механизм, который сохраняет результат предыдущих шагов сборки для повторного использования в будущих сборках. Когда Docker создает образ, он последовательно выполняет инструкции в файле Dockerfile. Если контекст шага (его команды и входные данные) не изменился с момента последней сборки, Docker повторно использует кэшированный результат вместо того, чтобы выполнять шаг снова.

## **Как использовать кэш сборки Docker**

Чтобы оптимизировать использование кэша сборки Docker, структурируйте файл Dockerfile таким образом, чтобы шаги, которые изменяются реже, выполнялись перед шагами, которые изменяются чаще.

## **Пример оптимизации кэша**

```docker
# Base image that changes rarely
FROM python:3.8-slim

# Install dependencies that change rarely
COPY requirements.txt .
RUN pip install -r requirements.txt
# Copy source code last, as it changes more frequently
COPY . /app
```

В этом примере базовый образ и зависимости с меньшей вероятностью изменятся по сравнению с исходным кодом. Копируя исходный код после установки зависимостей, вы гарантируете, что кэш для установки зависимостей можно использовать повторно, если `requirements.txt` не изменится.

## **Когда следует использовать оптимизацию кэша**

- **Разработка:** Во время локальной разработки при частом сборе образов для ускорения процесса сборки.
- **Конвейеры CI/CD:** в конвейерах CI/CD для сокращения времени сборки и потребления ресурсов, особенно когда сборки запускаются изменениями исходного кода, которые не влияют на зависимости или базовый образ.

## **Рекомендации**

- **Упорядочивайте инструкции с умом:** Размещайте инструкции, которые с меньшей вероятностью изменятся (например, установка пакетов), перед инструкциями, которые меняются чаще (например, копирование исходного кода).
- **Свести к минимуму изменения слоев:** Группируйте связанные команды, чтобы свести к минимуму количество слоев и уменьшить частоту изменений, которые делают кэш недействительным.
- **Используйте явные версии:** для базовых образов и пакетов используйте явные версии вместо тегов, таких как `latest`, чтобы обеспечить повторяемость и лучшее использование кэша.

## **Распространенные подводные камни**

- **Слишком раннее аннулирование кэша:** изменение строки в файле Dockerfile, которое влияет на все последующие слои, может привести к ненужному аннулированию кэша, что приведет к увеличению времени сборки.
    
- **Игнорирование размера контекста сборки:** большой контекст сборки может замедлить процесс отправки контекста демону Docker, даже если кэш используется эффективно.
    
    Используйте `.dockerignore` для исключения ненужных файлов.
    

## **Ссылки по теме**

- Рекомендации по работе с Dockerfile: [https://docs.docker.com/develop/develop-images/dockerfile_best-practices/](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)
- Использование кэша сборки: [https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache)

# **8. Ограничение ресурсов контейнера**

Эффективное управление ресурсами контейнеров имеет решающее значение в общей среде, где несколько контейнеров работают на одном узле. Docker предоставляет механизмы для ограничения ресурсов ЦП и памяти, которые может использовать контейнер, гарантируя, что ни один контейнер не сможет монополизировать системные ресурсы, что может привести к снижению производительности или нестабильности системы.

## **Что такое ограничение ресурсов?**

Ограничение ресурсов в Docker включает в себя установку ограничений на объем ЦП и памяти, которые может использовать контейнер. Эти ограничения не позволяют контейнеру использовать больше выделенной ему доли системных ресурсов, что позволяет улучшить сосуществование контейнеров и повысить предсказуемость производительности приложений.

## **Как использовать ограничение ресурсов**

Чтобы ограничить ресурсы для контейнера, вы можете использовать `--cpus`, `--memory` (или `-m`), `--memory-swap` и другие флаги при запуске контейнера с `docker run`.

## **Пример: ограничение ЦП и памяти**

```bash
docker run -it --cpus="1.5" --memory="500m" myapp:latest
```

Эта команда ограничивает контейнер до 1,5 ЦП и 500 МБ памяти. Эти ограничения гарантируют, что контейнер не сможет чрезмерно потреблять ресурсы в ущерб другим контейнерам или хост-системе.

## **Когда следует использовать ограничение ресурсов**

- **Многоконтейнерные среды:** необходимы в производственных средах, где несколько контейнеров работают на одном хосте для обеспечения справедливого распределения ресурсов.
- **Тестирование производительности:** моделирование различных сценариев доступности ресурсов и проверка производительности приложений при различных ограничениях.
- **Ресурсоемкие приложения:** Для приложений, о которых известно, что они потребляют значительные ресурсы ЦП или памяти, чтобы предотвратить их влияние на хост-систему или другие приложения.

## **Рекомендации**

- **Правильное распределение:** Выделите достаточно ресурсов, чтобы приложение могло адекватно работать в нормальных условиях.
    
    Слишком строгие ограничения могут привести к снижению производительности приложения.
    
- **Мониторинг и настройка:** Непрерывно отслеживайте использование ресурсов контейнерами и при необходимости корректируйте лимиты на основе фактических шаблонов использования и требований к производительности.
    
- **Используйте Compose для нескольких контейнеров:** при управлении несколькими контейнерами используйте Docker Compose для определения ограничений ресурсов в файле `docker-compose.yml`, что упрощает управление и обеспечивает согласованность.
    

## **Распространенные подводные камни**

- **Чрезмерное выделение:** установка слишком высоких лимитов ресурсов может свести на нет преимущества изоляции, что может привести к чрезмерному потреблению ресурсов контейнерами.
- **Игнорирование подкачки:** Будьте осторожны с настройками подкачки (`-memory-swap`), так как разрешение слишком большого количества подкачки может привести к перегрузке диска и снижению производительности.
- **Отсутствие мониторинга:** Отсутствие мониторинга фактического использования ресурсов может привести к плохо оптимизированным настройкам, либо к чрезмерному или недостаточному ограничению ресурсов контейнера.

## **Ссылки по теме**

- Справочник по Docker Run (ограничения ресурсов): [https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources](https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources)
- Справочник по файлу Docker Compose (Ресурсы): [https://docs.docker.com/compose/compose-file/compose-file-v3/#resources](https://docs.docker.com/compose/compose-file/compose-file-v3/#resources)

# **9. События Docker для мониторинга**

События Docker предоставляют информацию в режиме реального времени от управляющей программы Docker, позволяя получить представление о действиях, происходящих в среде Docker. Эта функция может быть полезна для мониторинга, отладки и автоматизации реакции на различные события жизненного цикла Docker.

## **Что такое события Docker?**

События Docker — это поток структурированных данных, представляющий изменения состояния или действия объектов Docker, таких как контейнеры, образы, тома и сети. Каждое событие содержит информацию о типе объекта, выполненном действии и времени действия. Мониторинг этих событий может помочь вам понять, как с течением времени манипулируются объекты Docker, и может инициировать автоматизированные рабочие процессы на основе определенных действий.

## **Как использовать события Docker для мониторинга**

Чтобы отслеживать события Docker, используйте команду `docker events`. Вы можете отфильтровать поток событий по типу объекта, типу события или определенным атрибутам.

## **Пример: мониторинг событий контейнера**

```bash
docker events --filter 'type=container'
```

Эта команда фильтрует поток событий, чтобы отображались только события, связанные с контейнером, такие как создание, запуск, остановка и уничтожение.

## **Пример расширенной фильтрации**

Вы можете комбинировать несколько фильтров, чтобы сузить круг интересующих вас событий. Например, для мониторинга событий запуска и остановки контейнеров с тегом `prod`:

```bash
docker events --filter 'type=container' --filter 'event=start' --filter 'event=stop' --filter 'label=environment=prod'
```

## **Когда следует использовать события Docker**

- **Мониторинг в режиме реального времени:** для отслеживания того, что происходит в вашей среде Docker в режиме реального времени.
- **Отладка:** для диагностики проблем путем понимания последовательности событий, ведущих к ошибке или непредвиденному состоянию.
- **Автоматизация:** для запуска скриптов или уведомлений на основе определенных событий Docker, улучшения конвейеров CI/CD или рабочих процессов.

## **Рекомендации**

- **Выборочный мониторинг:** используйте фильтры, чтобы сосредоточиться на событиях, наиболее релевантных вашим потребностям, снижая уровень шума и облегчая выявление значимых действий.
- **Журнал событий:** рассмотрите возможность регистрации событий в файле или центральной системе ведения журнала для исторического анализа и аудита.
- **Интеграция с инструментами мониторинга:** используйте API Docker или сторонние инструменты, которые могут использовать события Docker для интеграции с общей стратегией мониторинга.

## **Распространенные подводные камни**

- **Влияние на производительность:** непрерывный мониторинг всех событий без фильтрации может привести к снижению производительности.
    
    Будьте избирательны в том, что вы контролируете.
    
- **Чрезмерная зависимость от интерфейса командной строки:** Для долгосрочного мониторинга или сложных сред использование только интерфейса командной строки для мониторинга событий может быть немасштабируемым.
    
    Изучайте возможности с помощью API Docker или специализированных инструментов мониторинга.
    

## **Ссылки по теме**

- Документация по событиям Docker: [https://docs.docker.com/engine/reference/commandline/events/](https://docs.docker.com/engine/reference/commandline/events/)
- Поток событий Docker API: [https://docs.docker.com/engine/api/v1.41/#tag/Events](https://docs.docker.com/engine/api/v1.41/#tag/Events)

# **10. Запуск контейнеров в режиме “только для чтения”**

Запуск контейнеров Docker в режиме только для чтения — это рекомендация по обеспечению безопасности, которая значительно снижает риск несанкционированного изменения файловой системы контейнера. Такой подход может помочь предотвратить вредоносные попытки изменить работающее приложение или его среду, что делает контейнеры более устойчивыми к атакам.

## **Что такое режим “только для чтения” для контейнеров?**

Режим «только для чтения» для контейнеров Docker означает, что файловая система контейнера монтируется как доступная только для чтения. В этом режиме контейнер и приложения в нем могут читать файлы, но не могут записывать или изменять файловую систему. Это помогает гарантировать, что приложение работает с минимально необходимыми привилегиями, повышая безопасность.

## **Как использовать режим «только для чтения»**

Чтобы запустить контейнер в режиме только для чтения, используйте флаг `--read-only` при запуске контейнера с `docker run`. Вот простой пример:

```bash
docker run --read-only -d myimage:latest
```

## **Решение проблем, связанных с возможностью записи**

Некоторым приложениям может потребоваться запись в определенные каталоги для получения временных данных или журналов. Вы можете решить эту проблему, подключив определенные каталоги как временные файловые системы (tmpfs) или как тома, доступные для записи. Вот как смонтировать tmpfs для `/tmp`:

```bash
docker run --read-only --tmpfs /tmp -d myimage:latest
```

## **Когда следует использовать режим только для чтения**

- **Приложения, чувствительные к безопасности:** особенно для приложений, которые обрабатывают конфиденциальные данные или доступны к Интернету.
- **Приложения без сохранения состояния:** Приложения, разработанные для работы без сохранения состояния, являются идеальными кандидатами для режима только для чтения, поскольку им не нужно сохранять данные.
- **Обеспечение неизменяемости:** Когда вы хотите внедрить парадигму неизменяемой инфраструктуры, убедитесь, что контейнеры остаются неизменными по сравнению с их исходным состоянием.

## **Рекомендации**

- **Определите требования, которые можно записывать:** Оцените свое приложение, чтобы определить каталоги, которым действительно требуется доступ на запись.
    
    Используйте тома или монтирование tmpfs для обеспечения записываемых путей там, где это необходимо.
    
- **Всестороннее тестирование:** тщательно протестируйте приложение в режиме “только для чтения”, чтобы выявить любые проблемы или необходимые корректировки перед развертыванием в рабочей среде.
    
- **Сочетание с другими методами обеспечения безопасности:** используйте режим “только для чтения” в рамках комплексной стратегии безопасности, включая использование пользователей без привилегий root, минимальное количество базовых образов и отказ от неиспользуемых возможностей.
    

## **Распространенные подводные камни**

- **Непредвиденные сбои приложений:** приложения, не предназначенные для подобных сред, могут неожиданно завершиться сбоем.
    
    Требуется тщательная подготовка и тестирование.
    
- **Ведение журнала и кэширование:** Обеспечьте альтернативные варианты ведения журнала и кэширования механизмов, требующих доступа на запись.
    

## **Ссылки по теме**

- Справочник по запуску Docker для контейнеров только для чтения: [https://docs.docker.com/engine/reference/commandline/run/#mount-volume--v---read-only](https://docs.docker.com/engine/reference/commandline/run/#mount-volume--v---read-only)
- Рекомендации по безопасности Docker: [https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#security](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#security)

# **11. Очистка с помощью Docker Prune**

Со временем в средах Docker могут накапливаться неиспользуемые образы, контейнеры, тома и сети, что приводит к нерациональному использованию дискового пространства и загромождению системных представлений. Команды `prune` Docker предлагают простой способ очистки этих неиспользуемых ресурсов, помогая поддерживать порядок и эффективность среды Docker.

## **Что такое Docker Prune?**

Docker Prune — это набор команд, предназначенных для удаления неиспользуемых объектов Docker. Он включает в себя параметры для удаления образов, контейнеров, томов, сетей и сборки кэша. Эти команды особенно полезны для освобождения места на диске и устранения беспорядка в средах разработки, промежуточной и производственной средах.

## **Как использовать Docker Prune**

## **Очистка контейнеров**

Чтобы удалить все остановленные контейнеры:

```bash
docker container prune
```

## **Очистка образов**

Чтобы удалить неиспользуемые образы (как висячие, так и не связанные с каким-либо контейнером):

```bash
docker image prune -a
```

## **Очистка волюмов**

Чтобы удалить все неиспользуемые тома, выполните следующие действия.

```
docker volume prune
```

## **Очистка сетей**

Чтобы удалить все неиспользуемые сети:

```
docker network prune
```

## **Очистка всего**

Чтобы очистить контейнеры, образы, тома и сети за один раз, выполните следующие действия.

```
docker system prune -a --volumes
```

## **Когда следует использовать Docker Prune**

- **Регулярное техническое обслуживание:** Периодически в средах разработки и производстве для освобождения дискового пространства.
- **После тестирования или спринта разработки:** для удаления временных контейнеров, образов и сетей, созданных во время разработки или тестирования.
- **Конвейеры CI/CD:** В рамках рабочих процессов CI/CD для обеспечения чистоты сред и минимизации требований к хранилищу.

## **Рекомендации**

- **Резервное копирование важных данных:** перед выполнением команд очистки томов убедитесь, что созданы резервные копии томов, содержащих важные данные.
    
- **Используйте с осторожностью в производственной среде:** Будьте осторожны при очистки в производственных условиях.
    
    Убедитесь, что команды prune не удаляют ресурсы, используемые в данный момент или необходимые для отката.
    
- **Автоматизируйте очистку:** рассмотрите возможность автоматизации очистка в безопасных средах (например, при разработке) для регулярной очистки неиспользуемых ресурсов.
    

## **Распространенные подводные камни**

- **Случайная потеря данных:** очистка томов может привести к необратимой потере данных, если важные тома не резервируются или не исключаются.
- **Удаление нужных образов:** Агрессивная очистка образов может привести к удалению образов, которые редко используются, но все же необходимы, что приведет к дополнительным затратам времени на повторное извлечение или перестроение образов.

## **Ссылки по теме**

- Документация по Docker Prune: [https://docs.docker.com/config/pruning/](https://docs.docker.com/config/pruning/)
- Рекомендации по управлению образами и контейнерами Docker: [https://docs.docker.com/develop/dev-best-practices/](https://docs.docker.com/develop/dev-best-practices/)

# **12. Переопределение точки входа для отладки**

Переопределение точки входа контейнера — это бесценный метод отладки и устранения неполадок в контейнерных приложениях. Это позволяет обойти процесс запуска приложения по умолчанию, указанный в файле Dockerfile, и вместо этого выполнять альтернативные команды, которые могут помочь диагностировать проблемы.

## **Что такое переопределение точки входа?**

При указании `ENTRYPOINT` в файле Dockerfile вы определяете исполняемый файл по умолчанию для контейнера. Переопределение точки входа во время запуска контейнера позволяет запустить контейнер с помощью другого исполняемого файла или команды, что может быть особенно полезно для проверки среды контейнера или запуска средств отладки в файловой системе контейнера.

## **Как использовать переопределение точки входа**

Вы можете переопределить точку входа контейнера с помощью флага `--entrypoint` с `docker run`. Вот как запустить контейнер с интерактивной оболочкой, минуя точку входа по умолчанию:

```bash
docker run --entrypoint /bin/sh -it myimage:latest
```

Эта команда запускает контейнер с `/bin/sh` в качестве точки входа, предоставляя вам интерактивный доступ к контейнеру в оболочке.

## **Пример: Отладка с альтернативной точкой входа**

Предположим, у вас есть приложение, которое завершается сбоем вскоре после запуска, и вы подозреваете проблему с конфигурацией. Вы можете переопределить точку входа, чтобы проверить среду или файлы конфигурации перед запуском приложения:

```bash
docker run --entrypoint /bin/sh -it myimage:latest -c "cat /app/config/app.conf"
```

## **Когда следует использовать переопределение точки входа**

- **Отладка:** Когда необходимо проверить файловую систему контейнера или взаимодействовать с ней перед запуском приложения.
- **Устранение неполадок при запуске:** Для диагностики проблем, возникающих в процессе запуска приложения.
- **Выполнение утилит или тестов:** Для выполнения утилит, скриптов или тестов, упакованных в контейнер, без запуска основного приложения.

## **Рекомендации**

- **Экономное использование в рабочей среде:** Переопределение точки входа в рабочей среде должно выполняться с осторожностью и в идеале только в контролируемом сеансе отладки.
- **Действия по отладке документа:** Если переопределение точки входа является частью процесса устранения неполадок, задокументируйте использованные шаги и команды для использования в будущем.
- **Сочетание с другими функциями Docker:** используйте другие функции Docker, такие как подключение томов, для помощи в процессе отладки.

## **Распространенные подводные камни**

- **Забывание состояния контейнера:** Помните, что изменения, внесенные в файловую систему контейнера при переопределении точки входа, не сохраняются, если они не зафиксированы в новом образе.
    
- **Влияние на поведение контейнера:** Переопределение точки входа может значительно изменить поведение контейнера.
    
    Убедитесь, что это не мешает ожидаемому поведению сети, связанным контейнерам или зависимостям служб.
    

## **Ссылки по теме**

- Документация по Docker ENTRYPOINT: [https://docs.docker.com/engine/reference/builder/#entrypoint](https://docs.docker.com/engine/reference/builder/#entrypoint)
- Справочник по запуску Docker: [https://docs.docker.com/engine/reference/run/](https://docs.docker.com/engine/reference/run/)

# **13. Контексты Docker для управления несколькими средами**

Контексты Docker — это относительно новая функция, которая упрощает управление несколькими средами Docker с одного клиента. Эта функция бесценна для разработчиков и инженеров DevOps, которые часто взаимодействуют с различными узлами Docker, включая локальные среды разработки, промежуточные и производственные среды у различных поставщиков облачных услуг.

## **Что такое контексты Docker?**

Контекст Docker хранит конфигурацию конечной точки Docker, например управляющей программы Docker, работающей на локальном компьютере, кластера Docker Swarm или кластера Kubernetes. Переключаясь между различными контекстами, вы можете легко указать интерфейс командной строки Docker на разные среды, не изменяя вручную переменные среды или файлы конфигурации.

## **Как использовать контексты Docker**

## **Создание нового контекста**

Вы можете создать новый контекст, указывающий на конкретную демон Docker или кластер Kubernetes, с помощью команды `docker context create`. Вот пример создания контекста для удаленного узла Docker:

```bash
docker context create remote-docker --docker "host=ssh://user@remote-server"
```

Эта команда создает новый контекст с именем `remote-docker`, который взаимодействует с демоном Docker на `remote-server` через SSH.

## **Переключение между контекстами**

Чтобы переключить активный контекст Docker, используйте команду `docker context use`:

```bash
docker context use remote-docker
```

После переключения контекстов все последующие команды Docker будут работать в среде `remote-docker`.

## **Контексты листинга**

Чтобы увидеть все доступные контексты и текущий активный контекст, используйте:

```bash
docker context ls
```

## **Когда следует использовать контексты Docker**

- **Развертывание в нескольких средах:** при управлении контейнерами в нескольких средах (разработке, промежуточной, производственной) или облачных провайдерах.
- **Удаленное управление Docker:** для управления ядрами Docker, работающими на удаленных узлах или в облаке, непосредственно с локального терминала.
- **Конвейеры CI/CD:** в конвейерах CI/CD для динамического переключения между различными средами Docker для сборки, тестирования и развертывания приложений.

## **Рекомендации**

- **Именование контекстов:** Используйте описательные имена для контекстов, чтобы легко идентифицировать целевую среду.
- **Безопасный доступ:** При настройке удаленных контекстов, особенно по SSH, убедитесь, что доступ защищен и учетные данные управляются должным образом.
- **Контекст в CI/CD:** при использовании контекстов Docker в сценариях CI/CD убедитесь, что переключение контекста четко указано и понятно, чтобы избежать развертывания в неправильной среде.

## **Распространенные подводные камни**

- **Забывание активного контекста:** Легко забыть текущий активный контекст, что может привести к выполнению действий в неправильной среде.
    
    Всегда проверяйте активный контекст перед выполнением важных команд.
    
- **Неправильная настройка:** неправильная настройка контекста может привести к проблемам с подключением или сбою развертывания.
    
    Перепроверьте контекстные конфигурации, особенно для удаленных сред.
    

## **Ссылки по теме**

- Документация по контексту Docker: [https://docs.docker.com/engine/context/working-with-contexts/](https://docs.docker.com/engine/context/working-with-contexts/)
- Управление несколькими узлами Docker: [https://docs.docker.com/engine/reference/commandline/context/](https://docs.docker.com/engine/reference/commandline/context

