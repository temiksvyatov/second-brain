---
date:
  - 11/09/2024 18:18
tags: 
cssclasses:
  - image-borders
  - neutral-pen-black
---
# Лекция
- Учебник М.Вербик “Путеводитель по современной эконометрике”
---
# Линейная алгебра
*Матрица** - это прямоугольная таблица чисел, элементы которой расположены в строках и столбцах. Матрицы широко используются в математике, физике, информатике и других областях для представления и решения различных задач.

### Обозначение

Матрица обычно обозначается заглавной буквой латинского алфавита, например, $A$. Элементы матрицы обозначаются строчной буквой с двумя индексами, где первый индекс указывает на номер строки, а второй - на номер столбца. Например, элемент матрицы $A$ на пересечении $i$-й строки и $j$-го столбца обозначается как $a_{ij}$.

### Размерность

Матрица имеет размерность $m \times n$, где:

* $m$ - количество строк,
* $n$ - количество столбцов.

Матрица размера $m \times n$ записывается в виде:

$$
A = \begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}
$$

### Виды матриц

Существует множество видов матриц, некоторые из них:

* **Квадратная матрица:** $m = n$.
* **Прямоугольная матрица:** $m \neq n$.
* **Вектор-строка:** $m = 1$.
* **Вектор-столбец:** $n = 1$.
* **Нулевая матрица:** все элементы равны нулю.
* **Единичная матрица:** квадратная матрица, у которой элементы главной диагонали равны единице, а остальные элементы равны нулю.
* **Диагональная матрица:** квадратная матрица, у которой все элементы вне главной диагонали равны нулю.
* **Треугольная матрица:** квадратная матрица, у которой все элементы выше (ниже) главной диагонали равны нулю.

### Операции над матрицами

* **Сложение матриц:** Определено для матриц одинаковой размерности. Сумма матриц $A$ и $B$ - это матрица $C$, элементы которой равны сумме соответствующих элементов матриц $A$ и $B$:

$$
C = A + B \implies c_{ij} = a_{ij} + b_{ij}
$$

* **Умножение матрицы на число:** Результатом умножения матрицы $A$ на число $\lambda$ является матрица $B$, элементы которой равны произведению соответствующих элементов матрицы $A$ на число $\lambda$:

$$
B = \lambda A \implies b_{ij} = \lambda a_{ij}
$$

* **Умножение матриц:** Определено для матриц, у которых количество столбцов первой матрицы равно количеству строк второй матрицы. Произведение матриц $A$ и $B$ - это матрица $C$, элементы которой вычисляются по формуле:

$$
C = A \cdot B \implies c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}
$$

* **Транспонирование матрицы:** Результатом транспонирования матрицы $A$ является матрица $A^T$, строки которой являются столбцами матрицы $A$, а столбцы - строками матрицы $A$:

$$
A^T = \begin{pmatrix}
a_{11} & a_{21} & \cdots & a_{m1} \\
a_{12} & a_{22} & \cdots & a_{m2} \\
\vdots & \vdots & \ddots & \vdots \\
a_{1n} & a_{2n} & \cdots & a_{mn}
\end{pmatrix}
$$

### Применение матриц

Матрицы широко используются в различных областях:

* **Линейная алгебра:** решение систем линейных уравнений, нахождение собственных значений и векторов, обращение матриц.
* **Геометрия:** представление преобразований (поворот, масштабирование, сдвиг).
* **Компьютерная графика:** работа с изображениями, моделирование 3D-объектов.
* **Экономика:** моделирование экономических систем, анализ данных.
* **Физика:** описание квантовых состояний, решение дифференциальных уравнений.

# Свойства операций над матрицами
### Сложение матриц

Пусть $A$, $B$ и $C$ - матрицы одинаковой размерности. Тогда:

1. **Коммутативность:**

$$
A + B = B + A
$$

2. **Ассоциативность:**

$$
(A + B) + C = A + (B + C)
$$

3. **Существование нейтрального элемента:**

Нулевая матрица $0$ является нейтральным элементом по сложению:

$$
A + 0 = A
$$

4. **Существование противоположного элемента:**

Для любой матрицы $A$ существует противоположная матрица $-A$, такая что:

$$
A + (-A) = 0
$$

### Умножение матрицы на число

Пусть $A$ и $B$ - матрицы одинаковой размерности, $\lambda$ и $\mu$ - числа. Тогда:

1. **Ассоциативность:**

$$
\lambda (\mu A) = (\lambda \mu) A
$$

2. **Дистрибутивность относительно сложения чисел:**

$$
(\lambda + \mu) A = \lambda A + \mu A
$$

3. **Дистрибутивность относительно сложения матриц:**

$$
\lambda (A + B) = \lambda A + \lambda B
$$

4. **Умножение на единицу:**

$$
1 \cdot A = A
$$

### Умножение матриц

Пусть $A$, $B$ и $C$ - матрицы соответствующих размерностей. Тогда:

1. **Ассоциативность:**

$$
(A \cdot B) \cdot C = A \cdot (B \cdot C)
$$

2. **Дистрибутивность относительно сложения:**

$$
A \cdot (B + C) = A \cdot B + A \cdot C
$$

$$
(A + B) \cdot C = A \cdot C + B \cdot C
$$

3. **Умножение на единичную матрицу:**

Если $A$ - квадратная матрица, то:

$$
A \cdot I = I \cdot A = A
$$

4. **Невыполнение коммутативности:**

В общем случае умножение матриц **не коммутативно**:

$$
A \cdot B \neq B \cdot A
$$

### Транспонирование матриц

Пусть $A$ и $B$ - матрицы соответствующих размерностей, $\lambda$ - число. Тогда:

1. **Транспонирование суммы:**

$$
(A + B)^T = A^T + B^T
$$

2. **Транспонирование произведения:**

$$
(A \cdot B)^T = B^T \cdot A^T
$$

3. **Транспонирование произведения на число:**

$$
(\lambda A)^T = \lambda A^T
$$

4. **Транспонирование транспонированной матрицы:**

$$
(A^T)^T = A
$$

---
# Теория вероятностей
- **Случайная величина** — переменная, которая в результате испытания в зависимости от случая принимает одно из возможного множества своих значений.
	- **Неприрывные**
	- **Дискретные**
- **Мат. ожидание**
- **Корреляция**
- **Ковариация**
## Свойства ковариации

**Ковариация** - это статистическая мера, которая показывает, как две случайные величины изменяются совместно. Она широко используется в статистике, теории вероятностей, финансах и других областях для анализа взаимосвязей между переменными.

### Определение

Пусть $X$ и $Y$ - две случайные величины. Ковариация между $X$ и $Y$ определяется как математическое ожидание произведения отклонений этих величин от их математических ожиданий:

$$
\text{Cov}(X, Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])]
$$

где:

* $\mathbb{E}[X]$ - математическое ожидание случайной величины $X$,
* $\mathbb{E}[Y]$ - математическое ожидание случайной величины $Y$.

### Свойства ковариации

Ковариация обладает рядом важных свойств:

1. **Ковариация симметрична:**

$$
\text{Cov}(X, Y) = \text{Cov}(Y, X)
$$

2. **Ковариация линейна по каждому аргументу:**

$$
\text{Cov}(aX + b, Y) = a \text{Cov}(X, Y)
$$

$$
\text{Cov}(X, cY + d) = c \text{Cov}(X, Y)
$$

где $a$, $b$, $c$ и $d$ - константы.

3. **Ковариация суммы случайных величин:**

$$
\text{Cov}(X_1 + X_2, Y) = \text{Cov}(X_1, Y) + \text{Cov}(X_2, Y)
$$

$$
\text{Cov}(X, Y_1 + Y_2) = \text{Cov}(X, Y_1) + \text{Cov}(X, Y_2)
$$

4. **Ковариация случайной величины с собой:**

$$
\text{Cov}(X, X) = \text{Var}(X)
$$

где $\text{Var}(X)$ - дисперсия случайной величины $X$.

5. **Ковариация с константой:**

$$
\text{Cov}(X, c) = 0
$$

где $c$ - константа.

6. **Неравенство Коши-Буняковского:**

$$
\text{Cov}^2(X, Y) \leq \text{Var}(X) \cdot \text{Var}(Y)
$$

7. **Коэффициент корреляции:**

Ковариация нормируется на произведение стандартных отклонений случайных величин $X$ и $Y$, чтобы получить **коэффициент корреляции** $\rho(X, Y)$:

$$
\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
$$

где $\sigma_X$ и $\sigma_Y$ - стандартные отклонения случайных величин $X$ и $Y$ соответственно. Коэффициент корреляции принимает значения от $-1$ до $1$ и показывает силу и направление линейной зависимости между $X$ и $Y$.

### Примеры

**Пример 1:** Пусть $X$ и $Y$ - две случайные величины с математическими ожиданиями $\mathbb{E}[X] = 2$ и $\mathbb{E}[Y] = 3$ соответственно. Найти ковариацию между $X$ и $Y$, если $\mathbb{E}[XY] = 10$.

$$
\text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X] \cdot \mathbb{E}[Y] = 10 - 2 \cdot 3 = 4
$$

**Пример 2:** Пусть $X$ и $Y$ - две независимые случайные величины. Найти ковариацию между $X$ и $Y$.

Так как $X$ и $Y$ независимы, то $\mathbb{E}[XY] = \mathbb{E}[X] \cdot \mathbb{E}[Y]$. Следовательно:

$$
\text{Cov}(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X] \cdot \mathbb{E}[Y] = \mathbb{E}[X] \cdot \mathbb{E}[Y] - \mathbb{E}[X] \cdot \mathbb{E}[Y] = 0
$$